# 딥러닝 기반 한국어 리뷰 감성 분석 모델

### 📌 프로젝트 개요
본 프로젝트는 한국어 텍스트(리뷰, 댓글 등)의 감성(긍정, 부정, 중립)을 효과적으로 분류하는 딥러닝 모델을 개발하는 것을 목표로 합니다.

### 📂 프로젝트 구조.
```
├── model/                  # 학습된 모델과 전처리기 객체를 저장하는 폴더
│   ├── model.h5            # 학습된 딥러닝 모델(구조 및 가중치) 파일
│   └── tokenizer.pickle    # 텍스트 전처리를 위한 단어 사전(Tokenizer) 객체
├── coolnjoyCrawler.py        # 커뮤니티 리뷰 데이터 수집을 위한 웹 크롤러
└── app.py                    # Streamlit 기반의 감성 분석 웹 애플리케이션 실행 파일
```
### 시작하기
1. 환경 설정
라이브러리 설치먼저 프로젝트에 필요한 라이브러리들을 설치합니다.
```
pip install pandas numpy scikit-learn tensorflow konlpy tqdm matplotlib seaborn
```
2. 실행
```
streamlit run app.py
```
3. 검색어 입력
원하는 그래픽카드 제품명을 입력 후 하단의 버튼을 클릭합니다.

### 데이터 수집
하드웨어 커뮤니티인 '쿨엔조이'의 그래픽카드 게시판에서 약 60만 개의 게시글 및 댓글 데이터를 수집했습니다.

### LLM을 활용한 자동 레이블링
60만 개가 넘는 방대한 양의 텍스트를 사람이 직접 분류하는 것은 현실적으로 어렵습니다. 
이 문제를 해결하기 위해 LG의 Exaone 거대 언어 모델(LLM)을 활용하여 감성 레이블링을 자동화했습니다.

### 텍스트 전처리
모델이 텍스트를 효과적으로 학습할 수 있도록 다음과 같은 순서로 데이터를 정제하고 변환합니다.

1. 정규식을 이용한 노이즈 제거: 한글, 공백을 제외한 모든 특수문자, 이모티콘, 한자 등을 제거하여 텍스트를 정제합니다.
2. 토큰화 (Tokenization): KoNLPy의 Okt 형태소 분석기를 사용하여 문장을 의미 있는 최소 단위인 형태소로 분할합니다. 어간 추출(stemming)을 통해 단어를 기본 형태로 변환합니다. (예: '재미있었어요' -> '재미있다')
3. 불용어 제거 (Stopword Removal): 문장에서 큰 의미가 없는 조사, 접사 등(예: '은', '는', '이', '가')을 정의된 불용어 사전을 기반으로 제거하여 중요한 단어만 남깁니다.
4. 정수 인코딩 (Integer Encoding): Tokenizer를 사용하여 각 단어에 고유한 정수 인덱스를 부여합니다. 훈련 데이터에 너무 적게 등장하는 희귀 단어는 단어 집합에서 제외하여 노이즈를 줄입니다.
5. 패딩 (Padding): 모델에 입력하기 위해 모든 문장의 길이를 동일하게 맞춰주는 과정입니다. 정해진 최대 길이(max_len)보다 짧은 문장은 앞부분을 0으로 채웁니다.

### 모델 아키텍처
본 프로젝트의 감성 분석 모델은 다음과 같은 구조로 설계되었습니다.
Embedding Layer: 단어를 고차원의 벡터로 변환 (Embedding Dim: 200)
Bidirectional LSTM Layer: 문장의 순방향 및 역방향 문맥 정보를 모두 학습 (Hidden Units: 128)
Bidirectional LSTM Layer: 더 깊은 수준의 문맥 정보 추출 (Hidden Units: 128)
Dropout Layer: 학습 과정에서 일부 뉴런을 비활성화하여 과적합 방지
Dense Layer (ReLU): 비선형성을 추가하여 모델의 표현력 강화Dropout Layer: 추가적인 과적합 방지
Dense Layer (Softmax): 최종적으로 '긍정', '부정', '중립' 각 클래스에 대한 확률을 출력
